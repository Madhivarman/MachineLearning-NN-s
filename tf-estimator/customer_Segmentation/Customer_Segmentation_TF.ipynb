{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from datetime import datetime \n",
    "import shutil\n",
    "\n",
    "from tensorflow import data\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn import make_export_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Defining Parameters##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "train_filename = [\"dummy_dataset.csv\"]\n",
    "test_filename = [\"dummy_dataset_test.csv\"]\n",
    "\n",
    "model_name = \"cluster-01\"\n",
    "\n",
    "resume = False\n",
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features we have selected:['Frequency', 'Monetary', 'Recency']\n",
      "Unused Features:['Unamed:0']\n"
     ]
    }
   ],
   "source": [
    "#print column values\n",
    "HEADER = ['Unamed:0','Frequency','Recency', 'Monetary']\n",
    "HEADER_DEFAULTS = [[0],[0.0],[0.0],[0.0]]\n",
    "FEATURE_NAMES = ['Frequency','Monetary','Recency']\n",
    "UNUSED_FEATURE_NAMES = list(set(HEADER) - set(FEATURE_NAMES))\n",
    "\n",
    "print(\"Input features we have selected:{features}\"\n",
    "\t\t.format(features=FEATURE_NAMES))\n",
    "print(\"Unused Features:{}\".format(UNUSED_FEATURE_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Parsing and Pre-processing Logic###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing and preprocessing logic\n",
    "def parse_csv_row(csv_row):\n",
    "\t#decode csv, convert dataset into tensor\n",
    "\tcolumns = tf.decode_csv(csv_row, record_defaults=HEADER_DEFAULTS)\n",
    "\tcolumns = [tf.expand_dims(tensor, -1) for tensor in columns]\n",
    "\tfeatures = dict(zip(HEADER, columns))\n",
    "\n",
    "\tfor column in UNUSED_FEATURE_NAMES:\n",
    "\t\tfeatures.pop(column)\n",
    "\n",
    "\treturn features\n",
    "\n",
    "def process_features(features):\n",
    "\n",
    "\tif process_features:\n",
    "\t\tfeatures = features\n",
    "\n",
    "\treturn features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Data Pipeling input Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pipeline input function\n",
    "def csv_input_fn(file_names, mode=tf.estimator.ModeKeys.TRAIN,\n",
    "\t\t\t\tskip_header_lines = 0,\n",
    "\t\t\t\tnum_epochs=None,\n",
    "\t\t\t\tbatch_size=200):\n",
    "\n",
    "\t\tshuffle = False\n",
    "\t\tprint(\"Data Input Function\")\n",
    "\t\tprint(\"=====================\")\n",
    "\t\tprint(\"Batch_Size:{}\".format(batch_size))\n",
    "\t\tprint(\"Epoch Count:{}\".format(num_epochs))\n",
    "\t\tprint(\"Shuffle:{}\".format(shuffle))\n",
    "\t\tprint(\"============================\")\n",
    "\n",
    "\t\tdataset = data. TextLineDataset(filenames= train_filename)\n",
    "\t\tdataset = dataset.skip(skip_header_lines)\n",
    "\n",
    "\t\tif shuffle:\n",
    "\t\t\tdataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "\n",
    "\t\tdataset = dataset.batch(batch_size)\n",
    "\t\tdataset = dataset.map(lambda csv_row: parse_csv_row(csv_row))\n",
    "\t\tdataset = dataset.map(lambda features: process_features(features))\n",
    "\n",
    "\t\tdataset = dataset.repeat(num_epochs)\n",
    "\t\titerator = dataset.make_one_shot_iterator()\n",
    "\n",
    "\t\tfeatures = iterator.get_next()\n",
    "\n",
    "\t\treturn features, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:200\n",
      "Epoch Count:None\n",
      "Shuffle:False\n",
      "============================\n",
      "Features read from CSV:['Monetary', 'Frequency', 'Recency']\n"
     ]
    }
   ],
   "source": [
    "features, _ = csv_input_fn(file_names = train_filename)\n",
    "print(\"Features read from CSV:{}\".format(list(features.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an Estimator ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build an estimator\n",
    "def create_estimator(run_config, hparams):\n",
    "\testimator = tf.contrib.learn.KMeansClustering(\n",
    "        num_clusters = hparams.num_clusters,\n",
    "        initial_clusters= tf.contrib.factorization.RANDOM_INIT,\n",
    "        distance_metric= tf.contrib.factorization.SQUARED_EUCLIDEAN_DISTANCE,\n",
    "        use_mini_batch=True,\n",
    "        mini_batch_steps_per_iteration=1,\n",
    "        kmeans_plus_plus_num_retries=10,\n",
    "        relative_tolerance=None,\n",
    "        config= run_config\n",
    "    )\n",
    "\n",
    "\tprint(\"\")\n",
    "\tprint(\"Estimator Type:{}\".format(type(estimator)))\n",
    "\n",
    "\treturn estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Experiment ##\n",
    "\n",
    "### a. create a Serving function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_serving_input_fn():\n",
    "    \n",
    "    SERVING_HEADER = ['renancy','freq','monetary']\n",
    "    SERVING_HEADER_DEFAULTS = [[0.0],[0.0],[0.0]]\n",
    "    \n",
    "    #shape=(?,), dtype=string\n",
    "    rows_string_tensor = tf.placeholder(dtype=tf.string,\n",
    "                                        shape=[None],\n",
    "                                        name=\"csv_rows\")\n",
    "    \n",
    "    #feeding rows_string_tensor value in the dictionary\n",
    "    receive_tensor = {'csv_rows':rows_string_tensor}\n",
    "    \n",
    "    #shape=(?,1), dtype=string\n",
    "    row_columns = tf.expand_dims(rows_string_tensor, -1)\n",
    "    \n",
    "    #<tf.Tensor 'DecodeCSV:0' shape=(?,1) dtype=float32>,<tf.Tensor 'DecodeCSV:1' shape=(?,1) dtype=float32>\n",
    "    #<tf.Tensor 'DecodeCSV:2' shape=(?,1) dtype=float32>\n",
    "    columns = tf.decode_csv(row_columns, record_defaults=SERVING_HEADER_DEFAULTS)\n",
    "    \n",
    "    #<tf.Tensor 'Expand_dims_1:0' shape=(?,1,1) dtype=float32>,<tf.Tensor 'Expand_dims_2:0' shape=(?,1,1) dtype=float32>\n",
    "    #<tf.Tensor 'Expand_dims_3:0' shape=(?,1,1) dtype=float32>\n",
    "    columns = [tf.expand_dims(tensor, -1) for tensor in columns]\n",
    "    \n",
    "    #{\"renancy\":<tf.Tensor 'Expand_dims_1:0' shape=(?,1,1) dtype=float32>,\n",
    "    #\"freq\":<tf.Tensor 'Expand_dims_2:0' shape=(?,1,1) dtype=float32> \n",
    "    #\"monetary\":<tf.Tensor 'Expand_dims_1:0' shape=(?,1,1) dtype=float32>}\n",
    "    features = dict(zip(SERVING_HEADER, columns))\n",
    "    \n",
    "    \n",
    "    #InputFnOps(features=None, labels=None, default_inputs={'csv_rows':<tf.Tensor 'csv_rows:0' shape=(?,) dtype=string>})\n",
    "    return tf.contrib.learn.InputFnOps(\n",
    "        process_features(features),\n",
    "        None,\n",
    "        receive_tensor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. creating a Serve Input Function in Updated Function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_serving_input_fn_vtwo():\n",
    "    feature_placeholders = {\n",
    "        'renancy': tf.placeholder(tf.float32, [None]),\n",
    "        'freq': tf.placeholder(tf.float32, [None]),\n",
    "        'monetary': tf.placeholder(tf.float32, [None])\n",
    "    }\n",
    "    features ={\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    \n",
    "    return tf.contrib.learn.InputFnOps(features, None, feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Create Experiment Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_experiment_fn(**experiment_args):\n",
    "    \n",
    "    def _experiment_fn(run_config, hparams):\n",
    "        \n",
    "        train_input_fn = lambda: csv_input_fn(\n",
    "            train_filename,\n",
    "            mode = tf.contrib.learn.ModeKeys.TRAIN,\n",
    "            num_epochs = hparams.num_epochs,\n",
    "            batch_size = hparams.batch_size*10\n",
    "        )\n",
    "        \n",
    "        eval_input_fn = lambda: csv_input_fn(\n",
    "            train_filenames,\n",
    "            mode = tf.contrib.learn.ModeKeys.EVAL,\n",
    "            num_epochs=1,\n",
    "            batch_size=hparams.batch_size\n",
    "        )\n",
    "        \n",
    "        estimator = create_estimator(run_config, hparams)\n",
    "        \n",
    "        return tf.contrib.learn.Experiment(\n",
    "            estimator,\n",
    "            train_input_fn = train_input_fn,\n",
    "            eval_input_fn = eval_input_fn,\n",
    "            eval_steps = None,\n",
    "            **experiment_args\n",
    "        )\n",
    "    \n",
    "    return _experiment_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating Hyperparameter Tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-ca4a4127e16a>:12: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "Model is Stored in Directory:trained_models/cluster-01\n"
     ]
    }
   ],
   "source": [
    "#set HParam and RunConfig\n",
    "hparams = tf.contrib.training.HParams(\n",
    "\tnum_epochs=1000,\n",
    "\tbatch_size=500,\n",
    "\tnum_clusters=3)\n",
    "\n",
    "model_dir = \"trained_models/{}\".format(model_name)\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "\tsave_checkpoints_steps=100,\n",
    "\ttf_random_seed=100000,\n",
    "\tmodel_dir = model_dir)\n",
    "\n",
    "print(\"Model is Stored in Directory:{}\".format(run_config.model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.Run Experiement ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Previous Artifacts....\n",
      "Training Started at 12:29:30\n",
      ".......................................\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': 100, '_evaluation_master': '', '_environment': 'local', '_tf_random_seed': 100000, '_session_config': None, '_num_ps_replicas': 0, '_master': '', '_model_dir': 'trained_models/cluster-01', '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_device_fn': None, '_keep_checkpoint_max': 5, '_num_worker_replicas': 0, '_task_type': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_save_checkpoints_secs': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EDF806EC50>, '_task_id': 0, '_train_distribute': None}\n",
      "\n",
      "Estimator Type:<class 'tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering'>\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:5000\n",
      "Epoch Count:1000\n",
      "Shuffle:False\n",
      "============================\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:loss = 110300.0, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 68.7193\n",
      "INFO:tensorflow:loss = 60201.473, step = 101 (1.456 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.5247\n",
      "INFO:tensorflow:loss = 59900.875, step = 201 (1.325 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.5565\n",
      "INFO:tensorflow:loss = 60164.67, step = 301 (1.416 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.1043\n",
      "INFO:tensorflow:loss = 59867.285, step = 401 (1.331 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.5251\n",
      "INFO:tensorflow:loss = 60152.195, step = 501 (1.380 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.8457\n",
      "INFO:tensorflow:loss = 59855.54, step = 601 (1.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.0985\n",
      "INFO:tensorflow:loss = 60147.4, step = 701 (1.386 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.091\n",
      "INFO:tensorflow:loss = 59848.152, step = 801 (1.297 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.0922\n",
      "INFO:tensorflow:loss = 60142.5, step = 901 (1.298 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.3175\n",
      "INFO:tensorflow:loss = 59839.87, step = 1001 (1.382 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.2804\n",
      "INFO:tensorflow:loss = 60135.09, step = 1101 (1.295 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.925\n",
      "INFO:tensorflow:loss = 59834.152, step = 1201 (1.371 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.6335\n",
      "INFO:tensorflow:loss = 60130.906, step = 1301 (1.304 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.2177\n",
      "INFO:tensorflow:loss = 59830.727, step = 1401 (1.295 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.3548\n",
      "INFO:tensorflow:loss = 60128.316, step = 1501 (1.401 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.4917\n",
      "INFO:tensorflow:loss = 59828.492, step = 1601 (1.290 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.3266\n",
      "INFO:tensorflow:loss = 60126.36, step = 1701 (1.365 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.7061\n",
      "INFO:tensorflow:loss = 59825.48, step = 1801 (1.303 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.9554\n",
      "INFO:tensorflow:loss = 60122.16, step = 1901 (1.300 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.5985\n",
      "INFO:tensorflow:loss = 59822.023, step = 2001 (1.416 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.4409\n",
      "INFO:tensorflow:loss = 60118.836, step = 2101 (1.342 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.7324\n",
      "INFO:tensorflow:loss = 59819.508, step = 2201 (1.414 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.8502\n",
      "INFO:tensorflow:loss = 60116.29, step = 2301 (1.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.4786\n",
      "INFO:tensorflow:loss = 59817.625, step = 2401 (1.292 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.0987\n",
      "INFO:tensorflow:loss = 60114.387, step = 2501 (1.349 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.567\n",
      "INFO:tensorflow:loss = 59816.176, step = 2601 (1.306 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.8092\n",
      "INFO:tensorflow:loss = 60112.867, step = 2701 (1.373 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.51\n",
      "INFO:tensorflow:loss = 59815.023, step = 2801 (1.291 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.806\n",
      "INFO:tensorflow:loss = 60110.855, step = 2901 (1.284 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.0038\n",
      "INFO:tensorflow:loss = 59812.46, step = 3001 (1.371 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.0491\n",
      "INFO:tensorflow:loss = 60108.535, step = 3101 (1.297 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.122\n",
      "INFO:tensorflow:loss = 59810.34, step = 3201 (1.368 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.5516\n",
      "INFO:tensorflow:loss = 60106.6, step = 3301 (1.306 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 67.085\n",
      "INFO:tensorflow:loss = 59808.234, step = 3401 (1.491 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.6609\n",
      "INFO:tensorflow:loss = 60104.742, step = 3501 (1.395 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3600 into trained_models/cluster-01\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 75.502\n",
      "INFO:tensorflow:loss = 59806.348, step = 3601 (1.325 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.8848\n",
      "INFO:tensorflow:loss = 60103.17, step = 3701 (1.371 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.6935\n",
      "INFO:tensorflow:loss = 59804.734, step = 3801 (1.287 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.3328\n",
      "INFO:tensorflow:loss = 60101.83, step = 3901 (1.364 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.4406\n",
      "INFO:tensorflow:loss = 59803.36, step = 4001 (1.291 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.9172\n",
      "INFO:tensorflow:loss = 60100.71, step = 4101 (1.317 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.3633\n",
      "INFO:tensorflow:loss = 59802.18, step = 4201 (1.363 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.7801\n",
      "INFO:tensorflow:loss = 60099.723, step = 4301 (1.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.0867\n",
      "INFO:tensorflow:loss = 59801.156, step = 4401 (1.368 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.8085\n",
      "INFO:tensorflow:loss = 60098.902, step = 4501 (1.356 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.3604\n",
      "INFO:tensorflow:loss = 59800.258, step = 4601 (1.365 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.823\n",
      "INFO:tensorflow:loss = 60098.14, step = 4701 (1.370 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.7898\n",
      "INFO:tensorflow:loss = 59799.47, step = 4801 (1.338 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.8064\n",
      "INFO:tensorflow:loss = 60097.5, step = 4901 (1.373 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 78.0689\n",
      "INFO:tensorflow:loss = 59798.777, step = 5001 (1.281 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.0902\n",
      "INFO:tensorflow:loss = 60096.945, step = 5101 (1.367 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.7757\n",
      "INFO:tensorflow:loss = 59798.145, step = 5201 (1.357 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.0134\n",
      "INFO:tensorflow:loss = 60096.32, step = 5301 (1.315 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.2879\n",
      "INFO:tensorflow:loss = 59797.297, step = 5401 (1.364 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.7323\n",
      "INFO:tensorflow:loss = 60095.28, step = 5501 (1.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.8366\n",
      "INFO:tensorflow:loss = 59796.016, step = 5601 (1.373 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.7221\n",
      "INFO:tensorflow:loss = 60094.25, step = 5701 (1.302 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.1336\n",
      "INFO:tensorflow:loss = 59794.867, step = 5801 (1.331 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.6027\n",
      "INFO:tensorflow:loss = 60093.344, step = 5901 (1.378 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.0538\n",
      "INFO:tensorflow:loss = 59793.83, step = 6001 (1.297 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.2957\n",
      "INFO:tensorflow:loss = 60092.465, step = 6101 (1.384 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.8953\n",
      "INFO:tensorflow:loss = 59792.9, step = 6201 (1.299 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.0901\n",
      "INFO:tensorflow:loss = 60091.71, step = 6301 (1.387 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.6864\n",
      "INFO:tensorflow:loss = 59791.93, step = 6401 (1.322 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.4709\n",
      "INFO:tensorflow:loss = 60090.76, step = 6501 (1.291 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.0647\n",
      "INFO:tensorflow:loss = 59790.734, step = 6601 (1.368 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.4231\n",
      "INFO:tensorflow:loss = 60089.77, step = 6701 (1.308 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.3346\n",
      "INFO:tensorflow:loss = 59789.633, step = 6801 (1.423 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.1927\n",
      "INFO:tensorflow:loss = 60088.805, step = 6901 (1.330 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.8602\n",
      "INFO:tensorflow:loss = 59788.125, step = 7001 (1.301 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.0777\n",
      "INFO:tensorflow:loss = 60087.21, step = 7101 (1.368 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.1988\n",
      "INFO:tensorflow:loss = 59786.414, step = 7201 (1.311 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.4581\n",
      "INFO:tensorflow:loss = 60085.77, step = 7301 (1.400 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.1171\n",
      "INFO:tensorflow:loss = 59784.85, step = 7401 (1.296 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.5962\n",
      "INFO:tensorflow:loss = 60084.42, step = 7501 (1.359 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.9901\n",
      "INFO:tensorflow:loss = 59783.406, step = 7601 (1.300 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.7259\n",
      "INFO:tensorflow:loss = 60083.203, step = 7701 (1.303 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.3216\n",
      "INFO:tensorflow:loss = 59782.008, step = 7801 (1.383 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.3709\n",
      "INFO:tensorflow:loss = 60081.92, step = 7901 (1.309 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 59657.742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................\n",
      "Training Finished at 12:31:19\n",
      "\n",
      "Training elapsed time:109.13211 Seconds\n"
     ]
    }
   ],
   "source": [
    "if not resume:\n",
    "\tprint(\"Removing Previous Artifacts....\")\n",
    "\tshutil.rmtree(model_dir, ignore_errors=True)\n",
    "else:\n",
    "\tprint(\"Resuming Training....\")\n",
    "\n",
    "\n",
    "if train:\n",
    "\ttf.logging.set_verbosity(tf.logging.INFO)\n",
    "\ttime_start = datetime.utcnow()\n",
    "\tprint(\"Training Started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "\tprint(\".......................................\")\n",
    "\n",
    "\tlearn_runner.run(\n",
    "        experiment_fn = generate_experiment_fn(\n",
    "            \n",
    "            export_strategies=[make_export_strategy(\n",
    "               csv_serving_input_fn_vtwo,\n",
    "                exports_to_keep =1\n",
    "            )]\n",
    "        ), #not executing export_savedmodel()\n",
    "        run_config = run_config,\n",
    "        schedule=\"train\",\n",
    "        hparams=hparams\n",
    "    ) \n",
    "\n",
    "\ttime_end = datetime.utcnow()\n",
    "\tprint(\".......................................\")\n",
    "\tprint(\"Training Finished at {}\".format(time_end. strftime(\"%H:%M:%S\")))\n",
    "\tprint(\"\")\n",
    "\n",
    "\ttime_elapsed = time_end - time_start\n",
    "\tprint(\"Training elapsed time:{} Seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Predictions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': 100, '_evaluation_master': '', '_environment': 'local', '_tf_random_seed': 100000, '_session_config': None, '_num_ps_replicas': 0, '_master': '', '_model_dir': 'trained_models/cluster-01', '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_device_fn': None, '_keep_checkpoint_max': 5, '_num_worker_replicas': 0, '_task_type': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_save_checkpoints_secs': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EDF806EC50>, '_task_id': 0, '_train_distribute': None}\n",
      "\n",
      "Estimator Type:<class 'tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering'>\n",
      "WARNING:tensorflow:From <ipython-input-14-73ed5999bd13>:16: KMeansClustering.predict_cluster_idx (from tensorflow.contrib.learn.python.learn.estimators.kmeans) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.contrib.factorization.KMeansClustering instead of tf.contrib.learn.KMeansClustering. It has a similar interface, but uses the tf.estimator.Estimator API instead of tf.contrib.learn.Estimator.\n",
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:1500\n",
      "Epoch Count:1\n",
      "Shuffle:False\n",
      "============================\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:500\n",
      "Epoch Count:1\n",
      "Shuffle:False\n",
      "============================\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "#perform predictions\n",
    "train_input_fn = lambda: csv_input_fn(\n",
    "\ttrain_filename,\n",
    "\tnum_epochs=1,\n",
    "\tbatch_size=1500)\n",
    "\n",
    "test_input_fn = lambda: csv_input_fn(\n",
    "    test_filename,\n",
    "    num_epochs=1,\n",
    "    batch_size = 500\n",
    "    )\n",
    "\n",
    "estimator = create_estimator(run_config, hparams)\n",
    "\n",
    "\n",
    "train_assignments = list(estimator.predict_cluster_idx(input_fn=train_input_fn))\n",
    "test_assignments = list(estimator.predict_cluster_idx(input_fn=test_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-24d56b984e69>:2: KMeansClustering.clusters (from tensorflow.contrib.learn.python.learn.estimators.kmeans) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.contrib.factorization.KMeansClustering instead of tf.contrib.learn.KMeansClustering. It has a similar interface, but uses the tf.estimator.Estimator API instead of tf.contrib.learn.Estimator.\n",
      "Cluster Centroids:\n",
      "=====================\n",
      "[[2.3320048 5.58356   4.7135463]\n",
      " [6.9585557 7.193507  5.0743465]\n",
      " [6.0553403 2.397514  5.261766 ]]\n"
     ]
    }
   ],
   "source": [
    "#print cluster centroids\n",
    "clusters = estimator.clusters()\n",
    "print(\"Cluster Centroids:\")\n",
    "print(\"=====================\")\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving via the Saved model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: trained_models/cluster-01/export\\temp-1535372719\\saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'trained_models/cluster-01/export\\\\1535372719'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "estimator.export_savedmodel(export_dir_base, serving_input_receiver_fn,\n",
    "                            strip_default_attrs=True)\n",
    "\"\"\"\n",
    "\n",
    "export_dir = model_dir + \"/export\"\n",
    "\n",
    "estimator.export_savedmodel(\n",
    "    export_dir_base = export_dir,\n",
    "    serving_input_fn=csv_serving_input_fn,\n",
    "    as_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1373: get_timestamped_export_dir (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1378: get_temp_export_dir (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1388: get_input_alternatives (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1402: get_output_alternatives (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1412: build_all_signature_defs (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\utils\\saved_model_export_utils.py:267: build_standardized_signature_def (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: trained_models/cluster-01/serve_fn_two\\temp-1535459551\\saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'trained_models/cluster-01/serve_fn_two\\\\1535459551'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_dir = model_dir + \"/serve_fn_two\"\n",
    "estimator.export_savedmodel(export_dir, csv_serving_input_fn_vtwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Predict the cluster to the Test Data in Saved Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Frequency': <tf.Tensor 'IteratorGetNext:0' shape=(?, 1) dtype=float32>,\n",
       " 'Monetary': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=float32>,\n",
       " 'Recency': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=float32>}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_NAME = 'cluster-01'\n",
    "LAST = $(ls trained_models/${MODEL_NAME}/export | tail -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
