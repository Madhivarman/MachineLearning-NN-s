{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from datetime import datetime \n",
    "import shutil\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow import data\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn import make_export_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Defining Parameters##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "train_filename = [\"dummy_dataset.csv\"]\n",
    "test_filename = [\"dummy_dataset_test.csv\"]\n",
    "\n",
    "model_name = \"cluster-01\"\n",
    "\n",
    "resume = False\n",
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features we have selected:['Frequency', 'Monetary', 'Recency']\n",
      "Unused Features:['Unamed:0']\n"
     ]
    }
   ],
   "source": [
    "#print column values\n",
    "HEADER = ['Unamed:0','Frequency','Recency', 'Monetary']\n",
    "HEADER_DEFAULTS = [[0],[0.0],[0.0],[0.0]]\n",
    "FEATURE_NAMES = ['Frequency','Monetary','Recency']\n",
    "UNUSED_FEATURE_NAMES = list(set(HEADER) - set(FEATURE_NAMES))\n",
    "\n",
    "print(\"Input features we have selected:{features}\"\n",
    "\t\t.format(features=FEATURE_NAMES))\n",
    "print(\"Unused Features:{}\".format(UNUSED_FEATURE_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Parsing and Pre-processing Logic###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing and preprocessing logic\n",
    "def parse_csv_row(csv_row):\n",
    "\t#decode csv, convert dataset into tensor\n",
    "\tcolumns = tf.decode_csv(csv_row, record_defaults=HEADER_DEFAULTS)\n",
    "\tcolumns = [tf.expand_dims(tensor, -1) for tensor in columns]\n",
    "\tfeatures = dict(zip(HEADER, columns))\n",
    "\n",
    "\tfor column in UNUSED_FEATURE_NAMES:\n",
    "\t\tfeatures.pop(column)\n",
    "\n",
    "\treturn features\n",
    "\n",
    "def process_features(features):\n",
    "\n",
    "\tif process_features:\n",
    "\t\tfeatures = features\n",
    "\n",
    "\treturn features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Data Pipeling input Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pipeline input function\n",
    "def csv_input_fn(file_names, mode=tf.estimator.ModeKeys.TRAIN,\n",
    "\t\t\t\tskip_header_lines = 0,\n",
    "\t\t\t\tnum_epochs=None,\n",
    "\t\t\t\tbatch_size=200):\n",
    "\n",
    "\t\tshuffle = False\n",
    "\t\tprint(\"Data Input Function\")\n",
    "\t\tprint(\"=====================\")\n",
    "\t\tprint(\"Batch_Size:{}\".format(batch_size))\n",
    "\t\tprint(\"Epoch Count:{}\".format(num_epochs))\n",
    "\t\tprint(\"Shuffle:{}\".format(shuffle))\n",
    "\t\tprint(\"============================\")\n",
    "\n",
    "\t\tdataset = data. TextLineDataset(filenames= train_filename)\n",
    "\t\tdataset = dataset.skip(skip_header_lines)\n",
    "\n",
    "\t\tif shuffle:\n",
    "\t\t\tdataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "\n",
    "\t\tdataset = dataset.batch(batch_size)\n",
    "\t\tdataset = dataset.map(lambda csv_row: parse_csv_row(csv_row))\n",
    "\t\tdataset = dataset.map(lambda features: process_features(features))\n",
    "\n",
    "\t\tdataset = dataset.repeat(num_epochs)\n",
    "\t\titerator = dataset.make_one_shot_iterator()\n",
    "\n",
    "\t\tfeatures = iterator.get_next()\n",
    "\n",
    "\t\treturn features, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:200\n",
      "Epoch Count:None\n",
      "Shuffle:False\n",
      "============================\n",
      "Features read from CSV:['Monetary', 'Frequency', 'Recency']\n"
     ]
    }
   ],
   "source": [
    "features, _ = csv_input_fn(file_names = train_filename)\n",
    "print(\"Features read from CSV:{}\".format(list(features.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an Estimator ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build an estimator\n",
    "def create_estimator(run_config, hparams):\n",
    "\testimator = tf.contrib.learn.KMeansClustering(\n",
    "        num_clusters = hparams.num_clusters,\n",
    "        initial_clusters= tf.contrib.factorization.RANDOM_INIT,\n",
    "        distance_metric= tf.contrib.factorization.SQUARED_EUCLIDEAN_DISTANCE,\n",
    "        use_mini_batch=True,\n",
    "        mini_batch_steps_per_iteration=1,\n",
    "        kmeans_plus_plus_num_retries=10,\n",
    "        relative_tolerance=None,\n",
    "        config= run_config\n",
    "    )\n",
    "\n",
    "\tprint(\"\")\n",
    "\tprint(\"Estimator Type:{}\".format(type(estimator)))\n",
    "\n",
    "\treturn estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Experiment ##\n",
    "\n",
    "### a. create a Serving function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_serving_input_fn():\n",
    "    \n",
    "    SERVING_HEADER = ['renancy','freq','monetary']\n",
    "    SERVING_HEADER_DEFAULTS = [[0.0],[0.0],[0.0]]\n",
    "    \n",
    "    rows_string_tensor = tf.placeholder(dtype=tf.string,\n",
    "                                        shape=[None],\n",
    "                                        name=\"csv_rows\")\n",
    "    \n",
    "    receive_tensor = {'csv_rows':rows_string_tensor}\n",
    "    \n",
    "    row_columns = tf.expand_dims(rows_string_tensor, -1)\n",
    "    columns = tf.decode_csv(row_columns, record_defaults=SERVING_HEADER_DEFAULTS)\n",
    "    columns = [tf.expand_dims(tensor, -1) for tensor in columns]\n",
    "    features = dict(zip(SERVING_HEADER, columns))\n",
    "    \n",
    "    \n",
    "    return tf.contrib.learn.InputFnOps(\n",
    "        process_features(features),\n",
    "        None,\n",
    "        receive_tensor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Create Experiment Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_experiment_fn(**experiment_args):\n",
    "    \n",
    "    def _experiment_fn(run_config, hparams):\n",
    "        \n",
    "        train_input_fn = lambda: csv_input_fn(\n",
    "            train_filename,\n",
    "            mode = tf.contrib.learn.ModeKeys.TRAIN,\n",
    "            num_epochs = hparams.num_epochs,\n",
    "            batch_size = hparams.batch_size*10\n",
    "        )\n",
    "        \n",
    "        eval_input_fn = lambda: csv_input_fn(\n",
    "            train_filenames,\n",
    "            mode = tf.contrib.learn.ModeKeys.EVAL,\n",
    "            num_epochs=1,\n",
    "            batch_size=hparams.batch_size\n",
    "        )\n",
    "        \n",
    "        estimator = create_estimator(run_config, hparams)\n",
    "        \n",
    "        return tf.contrib.learn.Experiment(\n",
    "            estimator,\n",
    "            train_input_fn = train_input_fn,\n",
    "            eval_input_fn = eval_input_fn,\n",
    "            eval_steps = None,\n",
    "            **experiment_args\n",
    "        )\n",
    "    \n",
    "    return _experiment_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating Hyperparameter Tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-ca4a4127e16a>:12: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "Model is Stored in Directory:trained_models/cluster-01\n"
     ]
    }
   ],
   "source": [
    "#set HParam and RunConfig\n",
    "hparams = tf.contrib.training.HParams(\n",
    "\tnum_epochs=1000,\n",
    "\tbatch_size=500,\n",
    "\tnum_clusters=3)\n",
    "\n",
    "model_dir = \"trained_models/{}\".format(model_name)\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "\tsave_checkpoints_steps=100,\n",
    "\ttf_random_seed=100000,\n",
    "\tmodel_dir = model_dir)\n",
    "\n",
    "print(\"Model is Stored in Directory:{}\".format(run_config.model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.Run Experiement ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Previous Artifacts....\n",
      "Training Started at 12:37:18\n",
      ".......................................\n",
      "WARNING:tensorflow:From <ipython-input-103-c5c3bdea48a0>:19: make_export_strategy (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\utils\\saved_model_export_utils.py:484: ExportStrategy.__new__ (from tensorflow.contrib.learn.python.learn.export_strategy) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.estimator.train_and_evaluate, and use tf.estimator.Exporter.\n",
      "WARNING:tensorflow:From <ipython-input-103-c5c3bdea48a0>:24: run (from tensorflow.contrib.learn.python.learn.learn_runner) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.estimator.train_and_evaluate.\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_is_chief': True, '_save_checkpoints_secs': None, '_task_type': None, '_train_distribute': None, '_master': '', '_model_dir': 'trained_models/cluster-01', '_save_checkpoints_steps': 100, '_evaluation_master': '', '_task_id': 0, '_environment': 'local', '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_tf_random_seed': 100000, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_session_config': None, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F1C017C780>, '_keep_checkpoint_max': 5}\n",
      "\n",
      "Estimator Type:<class 'tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering'>\n",
      "WARNING:tensorflow:From <ipython-input-102-4a93518518ad>:26: Experiment.__init__ (from tensorflow.contrib.learn.python.learn.experiment) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.estimator.train_and_evaluate. You will also have to convert to a tf.estimator.Estimator.\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:5000\n",
      "Epoch Count:1000\n",
      "Shuffle:False\n",
      "============================\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:loss = 110300.0, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.4017\n",
      "INFO:tensorflow:loss = 60201.473, step = 101 (1.420 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 64.757\n",
      "INFO:tensorflow:loss = 59900.875, step = 201 (1.545 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.7094\n",
      "INFO:tensorflow:loss = 60164.67, step = 301 (1.356 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 67.9507\n",
      "INFO:tensorflow:loss = 59867.285, step = 401 (1.474 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.1636\n",
      "INFO:tensorflow:loss = 60152.195, step = 501 (1.367 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 69.2652\n",
      "INFO:tensorflow:loss = 59855.54, step = 601 (1.443 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 66.7275\n",
      "INFO:tensorflow:loss = 60147.4, step = 701 (1.500 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.837\n",
      "INFO:tensorflow:loss = 59848.152, step = 801 (1.371 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.5972\n",
      "INFO:tensorflow:loss = 60142.5, step = 901 (1.416 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.6082\n",
      "INFO:tensorflow:loss = 59839.87, step = 1001 (1.340 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.0905\n",
      "INFO:tensorflow:loss = 60135.09, step = 1101 (1.298 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.6445\n",
      "INFO:tensorflow:loss = 59834.152, step = 1201 (1.396 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.2371\n",
      "INFO:tensorflow:loss = 60130.906, step = 1301 (1.346 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.8099\n",
      "INFO:tensorflow:loss = 59830.727, step = 1401 (1.414 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.5804\n",
      "INFO:tensorflow:loss = 60128.316, step = 1501 (1.305 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.344\n",
      "INFO:tensorflow:loss = 59828.492, step = 1601 (1.310 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 69.7176\n",
      "INFO:tensorflow:loss = 60126.36, step = 1701 (1.438 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.6456\n",
      "INFO:tensorflow:loss = 59825.48, step = 1801 (1.335 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.4983\n",
      "INFO:tensorflow:loss = 60122.16, step = 1901 (1.399 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.4394\n",
      "INFO:tensorflow:loss = 59822.023, step = 2001 (1.344 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.7443\n",
      "INFO:tensorflow:loss = 60118.836, step = 2101 (1.375 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.9253\n",
      "INFO:tensorflow:loss = 59819.508, step = 2201 (1.390 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.1754\n",
      "INFO:tensorflow:loss = 60116.29, step = 2301 (1.296 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 69.0953\n",
      "INFO:tensorflow:loss = 59817.625, step = 2401 (1.446 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 57.9082\n",
      "INFO:tensorflow:loss = 60114.387, step = 2501 (1.727 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.2873\n",
      "INFO:tensorflow:loss = 59816.176, step = 2601 (1.328 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 63.2392\n",
      "INFO:tensorflow:loss = 60112.867, step = 2701 (1.583 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.6329\n",
      "INFO:tensorflow:loss = 59815.023, step = 2801 (1.394 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2900 into trained_models/cluster-01\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 73.3561\n",
      "INFO:tensorflow:loss = 60110.855, step = 2901 (1.364 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 67.0894\n",
      "INFO:tensorflow:loss = 59812.46, step = 3001 (1.490 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.7998\n",
      "INFO:tensorflow:loss = 60108.535, step = 3101 (1.356 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 69.3259\n",
      "INFO:tensorflow:loss = 59810.34, step = 3201 (1.442 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.1824\n",
      "INFO:tensorflow:loss = 60106.6, step = 3301 (1.331 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 69.5359\n",
      "INFO:tensorflow:loss = 59808.234, step = 3401 (1.437 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.9365\n",
      "INFO:tensorflow:loss = 60104.742, step = 3501 (1.334 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.7517\n",
      "INFO:tensorflow:loss = 59806.348, step = 3601 (1.320 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 57.4748\n",
      "INFO:tensorflow:loss = 60103.17, step = 3701 (1.741 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 67.925\n",
      "INFO:tensorflow:loss = 59804.734, step = 3801 (1.471 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 66.2872\n",
      "INFO:tensorflow:loss = 60101.83, step = 3901 (1.509 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.0924\n",
      "INFO:tensorflow:loss = 59803.36, step = 4001 (1.428 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.5396\n",
      "INFO:tensorflow:loss = 60100.71, step = 4101 (1.378 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.4135\n",
      "INFO:tensorflow:loss = 59802.18, step = 4201 (1.400 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.7029\n",
      "INFO:tensorflow:loss = 60099.723, step = 4301 (1.339 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.8393\n",
      "INFO:tensorflow:loss = 59801.156, step = 4401 (1.302 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.8642\n",
      "INFO:tensorflow:loss = 60098.902, step = 4501 (1.391 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 73.609\n",
      "INFO:tensorflow:loss = 59800.258, step = 4601 (1.360 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.3632\n",
      "INFO:tensorflow:loss = 60098.14, step = 4701 (1.421 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.105\n",
      "INFO:tensorflow:loss = 59799.47, step = 4801 (1.330 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.8161\n",
      "INFO:tensorflow:loss = 60097.5, step = 4901 (1.374 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.7464\n",
      "INFO:tensorflow:loss = 59798.777, step = 5001 (1.303 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.951\n",
      "INFO:tensorflow:loss = 60096.945, step = 5101 (1.298 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.6562\n",
      "INFO:tensorflow:loss = 59798.145, step = 5201 (1.376 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.2297\n",
      "INFO:tensorflow:loss = 60096.32, step = 5301 (1.296 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.4284\n",
      "INFO:tensorflow:loss = 59797.297, step = 5401 (1.381 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.6737\n",
      "INFO:tensorflow:loss = 60095.28, step = 5501 (1.320 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.9512\n",
      "INFO:tensorflow:loss = 59796.016, step = 5601 (1.301 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.3433\n",
      "INFO:tensorflow:loss = 60094.25, step = 5701 (1.382 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.9514\n",
      "INFO:tensorflow:loss = 59794.867, step = 5801 (1.300 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.4994\n",
      "INFO:tensorflow:loss = 60093.344, step = 5901 (1.379 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.9521\n",
      "INFO:tensorflow:loss = 59793.83, step = 6001 (1.299 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.1632\n",
      "INFO:tensorflow:loss = 60092.465, step = 6101 (1.331 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.135\n",
      "INFO:tensorflow:loss = 59792.9, step = 6201 (1.385 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.8924\n",
      "INFO:tensorflow:loss = 60091.71, step = 6301 (1.301 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 70.8605\n",
      "INFO:tensorflow:loss = 59791.93, step = 6401 (1.412 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.6166\n",
      "INFO:tensorflow:loss = 60090.76, step = 6501 (1.321 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.6041\n",
      "INFO:tensorflow:loss = 59790.734, step = 6601 (1.290 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.2241\n",
      "INFO:tensorflow:loss = 60089.77, step = 6701 (1.384 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 75.6733\n",
      "INFO:tensorflow:loss = 59789.633, step = 6801 (1.322 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.3082\n",
      "INFO:tensorflow:loss = 60088.805, step = 6901 (1.311 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.6197\n",
      "INFO:tensorflow:loss = 59788.125, step = 7001 (1.396 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 76.4796\n",
      "INFO:tensorflow:loss = 60087.21, step = 7101 (1.307 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 71.4685\n",
      "INFO:tensorflow:loss = 59786.414, step = 7201 (1.401 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 64.9318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 60085.77, step = 7301 (1.538 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.1873\n",
      "INFO:tensorflow:loss = 59784.85, step = 7401 (1.386 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.6063\n",
      "INFO:tensorflow:loss = 60084.42, step = 7501 (1.289 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 74.3825\n",
      "INFO:tensorflow:loss = 59783.406, step = 7601 (1.342 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 72.7634\n",
      "INFO:tensorflow:loss = 60083.203, step = 7701 (1.374 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 78.0887\n",
      "INFO:tensorflow:loss = 59782.008, step = 7801 (1.282 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 77.3684\n",
      "INFO:tensorflow:loss = 60081.92, step = 7901 (1.293 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 59657.742.\n",
      ".......................................\n",
      "Training Finished at 12:39:11\n",
      "\n",
      "Training elapsed time:112.787961 Seconds\n"
     ]
    }
   ],
   "source": [
    "if not resume:\n",
    "\tprint(\"Removing Previous Artifacts....\")\n",
    "\tshutil.rmtree(model_dir, ignore_errors=True)\n",
    "else:\n",
    "\tprint(\"Resuming Training....\")\n",
    "\n",
    "\n",
    "if train:\n",
    "\ttf.logging.set_verbosity(tf.logging.INFO)\n",
    "\ttime_start = datetime.utcnow()\n",
    "\tprint(\"Training Started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "\tprint(\".......................................\")\n",
    "\n",
    "\tlearn_runner.run(\n",
    "        experiment_fn = generate_experiment_fn(\n",
    "            \n",
    "            export_strategies=[make_export_strategy(\n",
    "                csv_serving_input_fn,\n",
    "                exports_to_keep =1\n",
    "            )]\n",
    "        ), #not executing export_savedmodel()\n",
    "        run_config = run_config,\n",
    "        schedule=\"train\",\n",
    "        hparams=hparams\n",
    "    ) \n",
    "\n",
    "\ttime_end = datetime.utcnow()\n",
    "\tprint(\".......................................\")\n",
    "\tprint(\"Training Finished at {}\".format(time_end. strftime(\"%H:%M:%S\")))\n",
    "\tprint(\"\")\n",
    "\n",
    "\ttime_elapsed = time_end - time_start\n",
    "\tprint(\"Training elapsed time:{} Seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Predictions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_is_chief': True, '_save_checkpoints_secs': None, '_task_type': None, '_train_distribute': None, '_master': '', '_model_dir': 'trained_models/cluster-01', '_save_checkpoints_steps': 100, '_evaluation_master': '', '_task_id': 0, '_environment': 'local', '_log_step_count_steps': 100, '_num_worker_replicas': 0, '_tf_random_seed': 100000, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_session_config': None, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F1C017C780>, '_keep_checkpoint_max': 5}\n",
      "\n",
      "Estimator Type:<class 'tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering'>\n",
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:1500\n",
      "Epoch Count:1\n",
      "Shuffle:False\n",
      "============================\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:500\n",
      "Epoch Count:1\n",
      "Shuffle:False\n",
      "============================\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "#perform predictions\n",
    "train_input_fn = lambda: csv_input_fn(\n",
    "\ttrain_filename,\n",
    "\tnum_epochs=1,\n",
    "\tbatch_size=1500)\n",
    "\n",
    "test_input_fn = lambda: csv_input_fn(\n",
    "    test_filename,\n",
    "    num_epochs=1,\n",
    "    batch_size = 500\n",
    "    )\n",
    "\n",
    "estimator = create_estimator(run_config, hparams)\n",
    "\n",
    "\n",
    "train_assignments = list(estimator.predict_cluster_idx(input_fn=train_input_fn))\n",
    "test_assignments = list(estimator.predict_cluster_idx(input_fn=test_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centroids:\n",
      "=====================\n",
      "[[2.3320048 5.58356   4.7135463]\n",
      " [6.9585557 7.193507  5.0743465]\n",
      " [6.0553403 2.397514  5.261766 ]]\n"
     ]
    }
   ],
   "source": [
    "#print cluster centroids\n",
    "clusters = estimator.clusters()\n",
    "print(\"Cluster Centroids:\")\n",
    "print(\"=====================\")\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving via the Saved model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: trained_models/cluster-01/export\\temp-1534856415\\saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'trained_models/cluster-01/export\\\\1534856415'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_dir  = model_dir + \"/export\"\n",
    "\n",
    "estimator.export_savedmodel(\n",
    "    export_dir_base = export_dir,\n",
    "    serving_input_fn = csv_serving_input_fn,\n",
    "    as_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Predict the cluster to the Test Data in Saved Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Frequency': <tf.Tensor 'IteratorGetNext:0' shape=(?, 1) dtype=float32>,\n",
       " 'Monetary': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=float32>,\n",
       " 'Recency': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=float32>}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import predictor\n",
    "\n",
    "predict_fn = predictor.from_saved_model(export_dir)\n",
    "predictions = predict_fn(\n",
    "    {\"x\": [[6.4, 3.2, 4.5, 1.5],\n",
    "           [5.8, 3.1, 5.0, 1.7]]})\n",
    "print(predictions['scores'])\n",
    "\n",
    "\n",
    "'renancy','freq','monetary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01/export/1534856415\\variables\\variables\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Got unexpected keys in input_dict: {'freq', 'monetary', 'renancy'}\nexpected: {'csv_rows'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-907c4483902c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;34m\"renancy\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;34m\"freq\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;34m\"monetary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     })\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\predictor\\predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, input_dict)\u001b[0m\n\u001b[0;32m     68\u001b[0m       raise ValueError(\n\u001b[0;32m     69\u001b[0m           'Got unexpected keys in input_dict: {}\\nexpected: {}'.format(\n\u001b[1;32m---> 70\u001b[1;33m               unexpected_keys, expected_keys))\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Got unexpected keys in input_dict: {'freq', 'monetary', 'renancy'}\nexpected: {'csv_rows'}"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import predictor\n",
    "\n",
    "path_to_pb = \"trained_models/cluster-01/export/1534856415\"\n",
    "predict_fn = predictor.from_saved_model(path_to_pb)\n",
    "predictions = predict_fn({\n",
    "        \"renancy\":[5.0,4.0,6.0,7.0],\n",
    "        \"freq\":[7.0,3.0,6.0,8,0],\n",
    "        \"monetary\":[8.0,4.0,7.0,5.0]\n",
    "    })\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
