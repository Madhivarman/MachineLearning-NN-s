{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from datetime import datetime \n",
    "import shutil\n",
    "\n",
    "from tensorflow import data\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn import make_export_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Defining Parameters##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "train_filename = [\"dummy_dataset.csv\"]\n",
    "test_filename = [\"dummy_dataset_test.csv\"]\n",
    "\n",
    "model_name = \"cluster-01\"\n",
    "\n",
    "resume = False\n",
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features we have selected:['Frequency', 'Monetary', 'Recency']\n",
      "Unused Features:['Unamed:0']\n"
     ]
    }
   ],
   "source": [
    "#print column values\n",
    "HEADER = ['Unamed:0','Frequency','Recency', 'Monetary']\n",
    "HEADER_DEFAULTS = [[0],[0.0],[0.0],[0.0]]\n",
    "FEATURE_NAMES = ['Frequency','Monetary','Recency']\n",
    "UNUSED_FEATURE_NAMES = list(set(HEADER) - set(FEATURE_NAMES))\n",
    "\n",
    "print(\"Input features we have selected:{features}\"\n",
    "\t\t.format(features=FEATURE_NAMES))\n",
    "print(\"Unused Features:{}\".format(UNUSED_FEATURE_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Parsing and Pre-processing Logic###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing and preprocessing logic\n",
    "def parse_csv_row(csv_row):\n",
    "\t#decode csv, convert dataset into tensor\n",
    "\tcolumns = tf.decode_csv(csv_row, record_defaults=HEADER_DEFAULTS)\n",
    "\tcolumns = [tf.expand_dims(tensor, -1) for tensor in columns]\n",
    "\tfeatures = dict(zip(HEADER, columns))\n",
    "\n",
    "\tfor column in UNUSED_FEATURE_NAMES:\n",
    "\t\tfeatures.pop(column)\n",
    "\n",
    "\treturn features\n",
    "\n",
    "def process_features(features):\n",
    "\n",
    "\tif process_features:\n",
    "\t\tfeatures = features\n",
    "\n",
    "\treturn features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Data Pipeling input Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pipeline input function\n",
    "def csv_input_fn(file_names, mode=tf.estimator.ModeKeys.TRAIN,\n",
    "\t\t\t\tskip_header_lines = 0,\n",
    "\t\t\t\tnum_epochs=None,\n",
    "\t\t\t\tbatch_size=200):\n",
    "\n",
    "\t\tshuffle = False\n",
    "\t\tprint(\"Data Input Function\")\n",
    "\t\tprint(\"=====================\")\n",
    "\t\tprint(\"Batch_Size:{}\".format(batch_size))\n",
    "\t\tprint(\"Epoch Count:{}\".format(num_epochs))\n",
    "\t\tprint(\"Shuffle:{}\".format(shuffle))\n",
    "\t\tprint(\"============================\")\n",
    "\n",
    "\t\tdataset = data. TextLineDataset(filenames= train_filename)\n",
    "\t\tdataset = dataset.skip(skip_header_lines)\n",
    "\n",
    "\t\tif shuffle:\n",
    "\t\t\tdataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "\n",
    "\t\tdataset = dataset.batch(batch_size)\n",
    "\t\tdataset = dataset.map(lambda csv_row: parse_csv_row(csv_row))\n",
    "\t\tdataset = dataset.map(lambda features: process_features(features))\n",
    "\n",
    "\t\tdataset = dataset.repeat(num_epochs)\n",
    "\t\titerator = dataset.make_one_shot_iterator()\n",
    "\n",
    "\t\tfeatures = iterator.get_next()\n",
    "\n",
    "\t\treturn features, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:200\n",
      "Epoch Count:None\n",
      "Shuffle:False\n",
      "============================\n",
      "Features read from CSV:['Monetary', 'Frequency', 'Recency']\n"
     ]
    }
   ],
   "source": [
    "features, _ = csv_input_fn(file_names = train_filename)\n",
    "print(\"Features read from CSV:{}\".format(list(features.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an Estimator ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build an estimator\n",
    "def create_estimator(run_config, hparams):\n",
    "\testimator = tf.contrib.learn.KMeansClustering(\n",
    "        num_clusters = hparams.num_clusters,\n",
    "        initial_clusters= tf.contrib.factorization.RANDOM_INIT,\n",
    "        distance_metric= tf.contrib.factorization.SQUARED_EUCLIDEAN_DISTANCE,\n",
    "        use_mini_batch=True,\n",
    "        mini_batch_steps_per_iteration=1,\n",
    "        kmeans_plus_plus_num_retries=10,\n",
    "        relative_tolerance=None,\n",
    "        config= run_config\n",
    "    )\n",
    "\n",
    "\tprint(\"\")\n",
    "\tprint(\"Estimator Type:{}\".format(type(estimator)))\n",
    "\n",
    "\treturn estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Experiment ##\n",
    "\n",
    "### a. create a Serving function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_serving_input_fn():\n",
    "    \n",
    "    SERVING_HEADER = ['renancy','freq','monetary']\n",
    "    SERVING_HEADER_DEFAULTS = [[0.0],[0.0],[0.0]]\n",
    "    \n",
    "    #shape=(?,), dtype=string\n",
    "    rows_string_tensor = tf.placeholder(dtype=tf.string,\n",
    "                                        shape=[None],\n",
    "                                        name=\"csv_rows\")\n",
    "    \n",
    "    #feeding rows_string_tensor value in the dictionary\n",
    "    receive_tensor = {'csv_rows':rows_string_tensor}\n",
    "    \n",
    "    #shape=(?,1), dtype=string\n",
    "    row_columns = tf.expand_dims(rows_string_tensor, -1)\n",
    "    \n",
    "    #<tf.Tensor 'DecodeCSV:0' shape=(?,1) dtype=float32>,<tf.Tensor 'DecodeCSV:1' shape=(?,1) dtype=float32>\n",
    "    #<tf.Tensor 'DecodeCSV:2' shape=(?,1) dtype=float32>\n",
    "    columns = tf.decode_csv(row_columns, record_defaults=SERVING_HEADER_DEFAULTS)\n",
    "    \n",
    "    #<tf.Tensor 'Expand_dims_1:0' shape=(?,1,1) dtype=float32>,<tf.Tensor 'Expand_dims_2:0' shape=(?,1,1) dtype=float32>\n",
    "    #<tf.Tensor 'Expand_dims_3:0' shape=(?,1,1) dtype=float32>\n",
    "    columns = [tf.expand_dims(tensor, -1) for tensor in columns]\n",
    "    \n",
    "    #{\"renancy\":<tf.Tensor 'Expand_dims_1:0' shape=(?,1,1) dtype=float32>,\n",
    "    #\"freq\":<tf.Tensor 'Expand_dims_2:0' shape=(?,1,1) dtype=float32> \n",
    "    #\"monetary\":<tf.Tensor 'Expand_dims_1:0' shape=(?,1,1) dtype=float32>}\n",
    "    features = dict(zip(SERVING_HEADER, columns))\n",
    "    \n",
    "    \n",
    "    #InputFnOps(features=None, labels=None, default_inputs={'csv_rows':<tf.Tensor 'csv_rows:0' shape=(?,) dtype=string>})\n",
    "    return tf.contrib.learn.InputFnOps(\n",
    "        process_features(features),\n",
    "        None,\n",
    "        receive_tensor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. creating a Serve Input Function in Updated Function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_serving_input_fn_vtwo():\n",
    "    feature_placeholders = {\n",
    "        'renancy': tf.placeholder(tf.float32, [None]),\n",
    "        'freq': tf.placeholder(tf.float32, [None]),\n",
    "        'monetary': tf.placeholder(tf.float32, [None])\n",
    "    }\n",
    "    features = feature_placeholders\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(features,\n",
    "                                                    feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Create Experiment Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_experiment_fn(**experiment_args):\n",
    "    \n",
    "    def _experiment_fn(run_config, hparams):\n",
    "        \n",
    "        train_input_fn = lambda: csv_input_fn(\n",
    "            train_filename,\n",
    "            mode = tf.contrib.learn.ModeKeys.TRAIN,\n",
    "            num_epochs = hparams.num_epochs,\n",
    "            batch_size = hparams.batch_size*10\n",
    "        )\n",
    "        \n",
    "        eval_input_fn = lambda: csv_input_fn(\n",
    "            train_filenames,\n",
    "            mode = tf.contrib.learn.ModeKeys.EVAL,\n",
    "            num_epochs=1,\n",
    "            batch_size=hparams.batch_size\n",
    "        )\n",
    "        \n",
    "        estimator = create_estimator(run_config, hparams)\n",
    "        \n",
    "        return tf.contrib.learn.Experiment(\n",
    "            estimator,\n",
    "            train_input_fn = train_input_fn,\n",
    "            eval_input_fn = eval_input_fn,\n",
    "            eval_steps = None,\n",
    "            **experiment_args\n",
    "        )\n",
    "    \n",
    "    return _experiment_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating Hyperparameter Tuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is Stored in Directory:trained_models/cluster-01\n"
     ]
    }
   ],
   "source": [
    "#set HParam and RunConfig\n",
    "hparams = tf.contrib.training.HParams(\n",
    "\tnum_epochs=1000,\n",
    "\tbatch_size=500,\n",
    "\tnum_clusters=3)\n",
    "\n",
    "model_dir = \"trained_models/{}\".format(model_name)\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "\tsave_checkpoints_steps=100,\n",
    "\ttf_random_seed=100000,\n",
    "\tmodel_dir = model_dir)\n",
    "\n",
    "print(\"Model is Stored in Directory:{}\".format(run_config.model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.Run Experiement ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Previous Artifacts....\n",
      "Training Started at 11:39:36\n",
      ".......................................\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_model_dir': 'trained_models/cluster-01', '_environment': 'local', '_master': '', '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_is_chief': True, '_save_checkpoints_steps': 100, '_num_ps_replicas': 0, '_train_distribute': None, '_task_type': None, '_task_id': 0, '_tf_random_seed': 100000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000015F2F6C54A8>, '_num_worker_replicas': 0, '_evaluation_master': '', '_device_fn': None, '_session_config': None, '_save_checkpoints_secs': None, '_keep_checkpoint_every_n_hours': 10000}\n",
      "\n",
      "Estimator Type:<class 'tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering'>\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:5000\n",
      "Epoch Count:1000\n",
      "Shuffle:False\n",
      "============================\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:loss = 110300.0, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 27.6464\n",
      "INFO:tensorflow:loss = 60201.473, step = 101 (3.617 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 27.8607\n",
      "INFO:tensorflow:loss = 59900.875, step = 201 (3.589 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.4081\n",
      "INFO:tensorflow:loss = 60164.67, step = 301 (3.519 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 33.4379\n",
      "INFO:tensorflow:loss = 59867.285, step = 401 (2.992 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 27.6672\n",
      "INFO:tensorflow:loss = 60152.195, step = 501 (3.617 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 29.1235\n",
      "INFO:tensorflow:loss = 59855.54, step = 601 (3.431 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 27.1433\n",
      "INFO:tensorflow:loss = 60147.4, step = 701 (3.684 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 40.5707\n",
      "INFO:tensorflow:loss = 59848.152, step = 801 (2.466 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.288\n",
      "INFO:tensorflow:loss = 60142.5, step = 901 (3.100 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 31.3348\n",
      "INFO:tensorflow:loss = 59839.87, step = 1001 (3.188 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 36.988\n",
      "INFO:tensorflow:loss = 60135.09, step = 1101 (2.705 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.0082\n",
      "INFO:tensorflow:loss = 59834.152, step = 1201 (3.573 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.8444\n",
      "INFO:tensorflow:loss = 60130.906, step = 1301 (3.463 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28\n",
      "INFO:tensorflow:loss = 59830.727, step = 1401 (3.575 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 26.756\n",
      "INFO:tensorflow:loss = 60128.316, step = 1501 (3.734 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 31.6275\n",
      "INFO:tensorflow:loss = 59828.492, step = 1601 (3.163 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 33.9714\n",
      "INFO:tensorflow:loss = 60126.36, step = 1701 (2.944 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.7888\n",
      "INFO:tensorflow:loss = 59825.48, step = 1801 (3.473 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 29.7989\n",
      "INFO:tensorflow:loss = 60122.16, step = 1901 (3.357 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.1148\n",
      "INFO:tensorflow:loss = 59822.023, step = 2001 (3.558 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 29.5111\n",
      "INFO:tensorflow:loss = 60118.836, step = 2101 (3.387 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.9497\n",
      "INFO:tensorflow:loss = 59819.508, step = 2201 (3.036 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 38.1043\n",
      "INFO:tensorflow:loss = 60116.29, step = 2301 (2.623 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 31.2866\n",
      "INFO:tensorflow:loss = 59817.625, step = 2401 (3.196 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 33.7836\n",
      "INFO:tensorflow:loss = 60114.387, step = 2501 (2.960 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.0621\n",
      "INFO:tensorflow:loss = 59816.176, step = 2601 (3.120 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 29.2885\n",
      "INFO:tensorflow:loss = 60112.867, step = 2701 (3.413 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 29.0239\n",
      "INFO:tensorflow:loss = 59815.023, step = 2801 (3.446 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 34.0425\n",
      "INFO:tensorflow:loss = 60110.855, step = 2901 (2.939 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 38.8045\n",
      "INFO:tensorflow:loss = 59812.46, step = 3001 (2.575 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 38.6449\n",
      "INFO:tensorflow:loss = 60108.535, step = 3101 (2.589 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 46.9149\n",
      "INFO:tensorflow:loss = 59810.34, step = 3201 (2.132 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 45.1148\n",
      "INFO:tensorflow:loss = 60106.6, step = 3301 (2.217 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.6912\n",
      "INFO:tensorflow:loss = 59808.234, step = 3401 (3.484 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 25.9253\n",
      "INFO:tensorflow:loss = 60104.742, step = 3501 (3.857 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3600 into trained_models/cluster-01\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.6546\n",
      "INFO:tensorflow:loss = 59806.348, step = 3601 (3.373 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.3113\n",
      "INFO:tensorflow:loss = 60103.17, step = 3701 (3.532 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 31.6638\n",
      "INFO:tensorflow:loss = 59804.734, step = 3801 (3.157 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 31.511\n",
      "INFO:tensorflow:loss = 60101.83, step = 3901 (3.175 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.4478\n",
      "INFO:tensorflow:loss = 59803.36, step = 4001 (3.515 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 29.7502\n",
      "INFO:tensorflow:loss = 60100.71, step = 4101 (3.363 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 26.3101\n",
      "INFO:tensorflow:loss = 59802.18, step = 4201 (3.800 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 27.3935\n",
      "INFO:tensorflow:loss = 60099.723, step = 4301 (3.648 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 29.6131\n",
      "INFO:tensorflow:loss = 59801.156, step = 4401 (3.377 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.0905\n",
      "INFO:tensorflow:loss = 60098.902, step = 4501 (3.560 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 31.2703\n",
      "INFO:tensorflow:loss = 59800.258, step = 4601 (3.197 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 30.6497\n",
      "INFO:tensorflow:loss = 60098.14, step = 4701 (3.264 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.7554\n",
      "INFO:tensorflow:loss = 59799.47, step = 4801 (3.054 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 27.6954\n",
      "INFO:tensorflow:loss = 60097.5, step = 4901 (3.610 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 31.4982\n",
      "INFO:tensorflow:loss = 59798.777, step = 5001 (3.174 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 27.3562\n",
      "INFO:tensorflow:loss = 60096.945, step = 5101 (3.657 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 29.5355\n",
      "INFO:tensorflow:loss = 59798.145, step = 5201 (3.384 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.7942\n",
      "INFO:tensorflow:loss = 60096.32, step = 5301 (3.051 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.2106\n",
      "INFO:tensorflow:loss = 59797.297, step = 5401 (3.104 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.1237\n",
      "INFO:tensorflow:loss = 60095.28, step = 5501 (3.112 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 34.6799\n",
      "INFO:tensorflow:loss = 59796.016, step = 5601 (2.885 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 41.9637\n",
      "INFO:tensorflow:loss = 60094.25, step = 5701 (2.382 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 34.5857\n",
      "INFO:tensorflow:loss = 59794.867, step = 5801 (2.892 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 37.1494\n",
      "INFO:tensorflow:loss = 60093.344, step = 5901 (2.690 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 36.5164\n",
      "INFO:tensorflow:loss = 59793.83, step = 6001 (2.740 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 27.3281\n",
      "INFO:tensorflow:loss = 60092.465, step = 6101 (3.661 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.6258\n",
      "INFO:tensorflow:loss = 59792.9, step = 6201 (4.624 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 26.9783\n",
      "INFO:tensorflow:loss = 60091.71, step = 6301 (3.707 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 35.4264\n",
      "INFO:tensorflow:loss = 59791.93, step = 6401 (2.824 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.9657\n",
      "INFO:tensorflow:loss = 60090.76, step = 6501 (3.030 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 35.2324\n",
      "INFO:tensorflow:loss = 59790.734, step = 6601 (2.839 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 34.467\n",
      "INFO:tensorflow:loss = 60089.77, step = 6701 (2.901 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 37.3976\n",
      "INFO:tensorflow:loss = 59789.633, step = 6801 (2.674 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 28.6434\n",
      "INFO:tensorflow:loss = 60088.805, step = 6901 (3.491 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.8772\n",
      "INFO:tensorflow:loss = 59788.125, step = 7001 (3.041 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7100 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 39.1409\n",
      "INFO:tensorflow:loss = 60087.21, step = 7101 (2.555 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7200 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 31.2116\n",
      "INFO:tensorflow:loss = 59786.414, step = 7201 (3.204 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7300 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 40.5884\n",
      "INFO:tensorflow:loss = 60085.77, step = 7301 (2.465 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7400 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 36.969\n",
      "INFO:tensorflow:loss = 59784.85, step = 7401 (2.703 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7500 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 31.2894\n",
      "INFO:tensorflow:loss = 60084.42, step = 7501 (3.197 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7600 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 35.6147\n",
      "INFO:tensorflow:loss = 59783.406, step = 7601 (2.808 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7700 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 33.5456\n",
      "INFO:tensorflow:loss = 60083.203, step = 7701 (2.980 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7800 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.6251\n",
      "INFO:tensorflow:loss = 59782.008, step = 7801 (3.064 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7900 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 32.6667\n",
      "INFO:tensorflow:loss = 60081.92, step = 7901 (3.062 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into trained_models/cluster-01\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 59657.742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................\n",
      "Training Finished at 11:43:54\n",
      "\n",
      "Training elapsed time:257.488087 Seconds\n"
     ]
    }
   ],
   "source": [
    "if not resume:\n",
    "\tprint(\"Removing Previous Artifacts....\")\n",
    "\tshutil.rmtree(model_dir, ignore_errors=True)\n",
    "else:\n",
    "\tprint(\"Resuming Training....\")\n",
    "\n",
    "\n",
    "if train:\n",
    "\ttf.logging.set_verbosity(tf.logging.INFO)\n",
    "\ttime_start = datetime.utcnow()\n",
    "\tprint(\"Training Started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "\tprint(\".......................................\")\n",
    "\n",
    "\tlearn_runner.run(\n",
    "        experiment_fn = generate_experiment_fn(\n",
    "            \n",
    "            export_strategies=[make_export_strategy(\n",
    "               csv_serving_input_fn_vtwo,\n",
    "                exports_to_keep =1\n",
    "            )]\n",
    "        ), #not executing export_savedmodel()\n",
    "        run_config = run_config,\n",
    "        schedule=\"train\",\n",
    "        hparams=hparams\n",
    "    ) \n",
    "\n",
    "\ttime_end = datetime.utcnow()\n",
    "\tprint(\".......................................\")\n",
    "\tprint(\"Training Finished at {}\".format(time_end. strftime(\"%H:%M:%S\")))\n",
    "\tprint(\"\")\n",
    "\n",
    "\ttime_elapsed = time_end - time_start\n",
    "\tprint(\"Training elapsed time:{} Seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Predictions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_log_step_count_steps': 100, '_model_dir': 'trained_models/cluster-01', '_environment': 'local', '_master': '', '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_is_chief': True, '_save_checkpoints_steps': 100, '_num_ps_replicas': 0, '_train_distribute': None, '_task_type': None, '_task_id': 0, '_tf_random_seed': 100000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000015F2F6C54A8>, '_num_worker_replicas': 0, '_evaluation_master': '', '_device_fn': None, '_session_config': None, '_save_checkpoints_secs': None, '_keep_checkpoint_every_n_hours': 10000}\n",
      "\n",
      "Estimator Type:<class 'tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering'>\n",
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:1500\n",
      "Epoch Count:1\n",
      "Shuffle:False\n",
      "============================\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Data Input Function\n",
      "=====================\n",
      "Batch_Size:500\n",
      "Epoch Count:1\n",
      "Shuffle:False\n",
      "============================\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "#perform predictions\n",
    "train_input_fn = lambda: csv_input_fn(\n",
    "\ttrain_filename,\n",
    "\tnum_epochs=1,\n",
    "\tbatch_size=1500)\n",
    "\n",
    "test_input_fn = lambda: csv_input_fn(\n",
    "    test_filename,\n",
    "    num_epochs=1,\n",
    "    batch_size = 500\n",
    "    )\n",
    "\n",
    "estimator = create_estimator(run_config, hparams)\n",
    "\n",
    "\n",
    "train_assignments = list(estimator.predict_cluster_idx(input_fn=train_input_fn))\n",
    "test_assignments = list(estimator.predict_cluster_idx(input_fn=test_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centroids:\n",
      "=====================\n",
      "[[2.3320048 5.58356   4.7135463]\n",
      " [6.9585557 7.193507  5.0743465]\n",
      " [6.0553403 2.397514  5.261766 ]]\n"
     ]
    }
   ],
   "source": [
    "#print cluster centroids\n",
    "clusters = estimator.clusters()\n",
    "print(\"Cluster Centroids:\")\n",
    "print(\"=====================\")\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving via the Saved model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1402: get_output_alternatives (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py:1412: build_all_signature_defs (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From c:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\utils\\saved_model_export_utils.py:267: build_standardized_signature_def (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cluster-01\\model.ckpt-8000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: trained_models/cluster-01/export\\temp-1535367508\\saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'trained_models/cluster-01/export\\\\1535367508'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "estimator.export_savedmodel(export_dir_base, serving_input_receiver_fn,\n",
    "                            strip_default_attrs=True)\n",
    "\"\"\"\n",
    "\n",
    "export_dir = model_dir + \"/export\"\n",
    "\n",
    "estimator.export_savedmodel(\n",
    "    export_dir_base = export_dir,\n",
    "    serving_input_fn=csv_serving_input_fn,\n",
    "    as_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-ecb2562febb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_savedmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_serving_input_fn_vtwo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mexport_savedmodel\u001b[1;34m(self, export_dir_base, serving_input_fn, default_output_alternative_key, assets_extra, as_text, checkpoint_path, graph_rewrite_specs, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1386\u001b[0m       \u001b[0minput_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserving_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m       input_alternatives, features = (\n\u001b[1;32m-> 1388\u001b[1;33m           saved_model_export_utils.get_input_alternatives(input_ops))\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m       \u001b[1;31m# TODO(b/34388557) This is a stopgap, pending recording model provenance.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m               instructions)\n\u001b[1;32m--> 250\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    252\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\madhivarman\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\utils\\saved_model_export_utils.py\u001b[0m in \u001b[0;36mget_input_alternatives\u001b[1;34m(input_ops)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0minput_alternatives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDEFAULT_INPUT_ALTERNATIVE_KEY\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munused_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "estimator.export_savedmodel(export_dir, csv_serving_input_fn_vtwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Predict the cluster to the Test Data in Saved Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Frequency': <tf.Tensor 'IteratorGetNext:0' shape=(?, 1) dtype=float32>,\n",
       " 'Monetary': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=float32>,\n",
       " 'Recency': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=float32>}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_NAME = 'cluster-01'\n",
    "LAST = $(ls trained_models/${MODEL_NAME}/export | tail -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
