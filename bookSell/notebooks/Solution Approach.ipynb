{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement ###\n",
    "\n",
    "With the previous month assortment and next month assortment we need to tell whether **we can pay our loan amount and next month book assortment?**\n",
    "\n",
    "The data we have is\n",
    "\n",
    "1. Customer Intrest Data.\n",
    "2. Original Purchase Order\n",
    "3. Product Features\n",
    "4. Last Month assortment\n",
    "5. Next Month assortment\n",
    "6. Next Purchase order\n",
    "\n",
    "### Solution Approach ###\n",
    "\n",
    "**last_month_assortment.csv** -> this data has historical records whether the customer bought the book or not. So, here column **purchased** act as a target variable. **Customer_Id, Product_Id** act as a primary key to map the customer intrests data and product features data.\n",
    "\n",
    "#### General logic for buying the books ####\n",
    "As we know in general, that customer will purchase the book according to their intrests and its price.\n",
    "\n",
    "#### Stepwise solution ####\n",
    "\n",
    "1. First step, is to find what is the loan amount we took? What is total amount we need to purchase for next assortment? How much money we did make selling in the previous month?\n",
    "\n",
    "2. Preprocess the customer intrests data. In **customer_features.csv** in the column \"favorite_genre\" customer has mentioned their book intrests. This play's a very important feature role whether the customer will buy the book or not!\n",
    "\n",
    "        2.1 first step is to check how many unique genres are there that customers like?\n",
    "        \n",
    "        2.2 if we are using this as a features to train a model, then it's necessary to convert into one-hot encoding rather than label encoding. Because, one customer can like multiple genres. So, converting into one-hot encoding is the best choice.\n",
    "            2.2.1 its important to remove unnecessary spaces in the word before converting to one-hot encoding. Otherwise, we might end up with duplicate columns.\n",
    "            \n",
    "        2.3 for analysis purpose, checking what genre has higher intrests? This simple insights might be helpful to intrepret model decision later.\n",
    "        \n",
    "        2.4 check what age people prefers reading the books most? From this analysis, we came to know people between age 36-55 likes to read a book more than other age people.\n",
    "        \n",
    "3. after converting into one-hot encoding, it important to know whether the book belongs to fiction (or) other categories.\n",
    "\n",
    "4. **last_month_assortment.csv** data is very important data, this tell us \"what book does actually purchased by customers?\" Because it tell's us that beyond their intrest whether they have purchased the book that are not entitiled with their intrests. It helps the model to capture those patterns too.\n",
    "\n",
    "5. after all the mapping is done, before we train a model **we need to do label encoding for the futures which are categorical. For example: features like is_returning_customer, fiction, purchased, genre, age_bucket**\n",
    "\n",
    "6. Before we start training a model, I saw this problem in two ways.\n",
    "\n",
    "        6.1 **Whether the customer will buy the book or not?**\n",
    "        6.2 **Whether the customer will buy the specific book or not?**\n",
    "        \n",
    "   for this problem statement, 2nd case is the right choice. Because in the data **next_month_assortment.csv** per customer we are sending 5 books. **we need to predict what book will customer buy?**. By predicting what book will customer buy, we can map the books which they are going to buy with their retail price and see what will be the **total amount** we are going to make out of from the next assortment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is ready, the next stage is to find the suitable model algorithm to get the best performance. After seeing the data, the first choice was **XGBClassifier**. Because the **XGBoost** works very well for categorical data and sparse data. I have tried other algorithms for similar dataset during work but found more promising result in XGBoost algorithm only. \n",
    "\n",
    "The other important task is to check **Model Stability** for the n_classes rather then the overall **accuracy**. Because, in our case its **binary classification** problem whether the customer will buy the book or not?. There's a chance that in our evaluation dataset **3/4 dataset belongs to class 0 and 1/4 belongs to class 1**. It's very important to check that model has ability to predict minority class too. \n",
    "\n",
    "In the case 3/4 class, if the model is predicting only **0** all the time, still the accuracy will be around **0.64%**. Checking **precision, recall, f1score** for each class and overall **auc** score is important. For now, the performance score is \n",
    "\n",
    "\n",
    "class|pre|rec|spe|f1|geo|iba|sup\n",
    "-----|---|---|---|--|---|---|---\n",
    "0|0.75|0.86|0.50|0.80|0.65|0.44|2285\n",
    "1|0.67|0.50|0.86|0.57|0.65|0.41|1315\n",
    "avg/total|0.72|0.73|0.63|0.72|0.65|0.43|3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Improvement ###\n",
    "\n",
    "From the model performance, we can see that the model not so performing well on class 1 as much it's performing on class 0. One way to improve the model performance is to **interpret the model decision.** With **Shap** library we can see the unified approach explanation to the output of the machine learning model. From this we can inspect the varience of the features and see the best features which has higher varience to get better prediction of the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
