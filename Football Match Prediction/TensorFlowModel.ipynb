{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Estimators ###\n",
    "\n",
    "A high level Tensorflow API that greatly simplify ML programming. It encapsulates following things\n",
    "\n",
    "1. Training\n",
    "2. Evaluating\n",
    "3. Prediction\n",
    "4. Export for Serving\n",
    "\n",
    "#### Structure of a Pre-Made Estimators Programs ####\n",
    "\n",
    "It typically consists of following 4 steps\n",
    "\n",
    "1. Convert CSV data into Tensorflow Records\n",
    "2. Define the Feature columns\n",
    "3. Create an relevant Algorithm\n",
    "4. Call a Training, Evaluation and Inference Method\n",
    "5. Export a serving function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shape:(12776, 28)\n",
      "Test Dataset Shape:(1530, 26)\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv('FinalData/finaldata.csv')\n",
    "test_data = pd.read_csv('FinalData/Testfinaldata.csv')\n",
    "\n",
    "train_filename = 'FinalData/finaldata.csv'\n",
    "test_filename = 'FinalData/TestFinaldata.csv'\n",
    "\n",
    "\n",
    "print(\"Training Dataset Shape:{}\".format(training_data.shape))\n",
    "print(\"Test Dataset Shape:{}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv Input function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_input_fn(features, labels, batch_size):\n",
    "    \n",
    "    #converts the inputs to dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    #shuffle\n",
    "    dataset =  dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \n",
    "    #input function for validation\n",
    "    features = dict(features)\n",
    "    \n",
    "    if labels is None:\n",
    "        #no labels only features\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "        \n",
    "    #convert inputs into dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    \n",
    "    assert batch_size is not None, \"Batch Size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an Estimator ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into train, test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#IMPORT COLUMNS\n",
    "important_columns = ['AC', 'AF', 'AR', 'AS', 'AST', 'AY', 'HC', 'HF',\n",
    "       'HR', 'HS', 'HST', 'HTAG', 'HTHG', 'HY','ht_label', 'at_label', 'league_label', \n",
    "        'HTCT', 'ATCT','HTWP', 'ATWP']\n",
    "\n",
    "\n",
    "#get input and output features\n",
    "X_all = training_data[important_columns]\n",
    "y_all = training_data['ftr_label']\n",
    "\n",
    "# Shuffle and split the dataset into training and testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    test_size = 100,\n",
    "                                                    random_state = 2,\n",
    "                                                    stratify = y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature columns\n",
    "my_feature_columns = []\n",
    "\n",
    "for key in important_columns:\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp4hit4amy\n",
      "INFO:tensorflow:Using config: {'_train_distribute': None, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_save_checkpoints_secs': 600, '_model_dir': 'C:\\\\Users\\\\MADHIV~1\\\\AppData\\\\Local\\\\Temp\\\\tmp4hit4amy', '_service': None, '_master': '', '_evaluation_master': '', '_global_id_in_cluster': 0, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_device_fn': None, '_num_worker_replicas': 1, '_task_type': 'worker', '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000235B50CCD30>, '_num_ps_replicas': 0, '_tf_random_seed': None, '_session_config': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp4hit4amy\\model.ckpt.\n",
      "INFO:tensorflow:loss = 40.190598, step = 0\n",
      "INFO:tensorflow:global_step/sec: 146.569\n",
      "INFO:tensorflow:loss = 16.298674, step = 100 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.686\n",
      "INFO:tensorflow:loss = 17.280857, step = 200 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.831\n",
      "INFO:tensorflow:loss = 17.654575, step = 300 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.08\n",
      "INFO:tensorflow:loss = 19.441063, step = 400 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.724\n",
      "INFO:tensorflow:loss = 18.046461, step = 500 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.097\n",
      "INFO:tensorflow:loss = 17.53932, step = 600 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.021\n",
      "INFO:tensorflow:loss = 17.574373, step = 700 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.004\n",
      "INFO:tensorflow:loss = 14.964988, step = 800 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.56\n",
      "INFO:tensorflow:loss = 15.375381, step = 900 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.485\n",
      "INFO:tensorflow:loss = 18.54486, step = 1000 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.135\n",
      "INFO:tensorflow:loss = 10.6026, step = 1100 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.897\n",
      "INFO:tensorflow:loss = 15.34179, step = 1200 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.869\n",
      "INFO:tensorflow:loss = 8.366622, step = 1300 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.449\n",
      "INFO:tensorflow:loss = 15.523206, step = 1400 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.138\n",
      "INFO:tensorflow:loss = 13.045084, step = 1500 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.96\n",
      "INFO:tensorflow:loss = 9.930751, step = 1600 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.905\n",
      "INFO:tensorflow:loss = 13.92871, step = 1700 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.148\n",
      "INFO:tensorflow:loss = 10.91651, step = 1800 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.716\n",
      "INFO:tensorflow:loss = 10.861439, step = 1900 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.792\n",
      "INFO:tensorflow:loss = 16.133816, step = 2000 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.042\n",
      "INFO:tensorflow:loss = 10.1117325, step = 2100 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.251\n",
      "INFO:tensorflow:loss = 12.241825, step = 2200 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.92\n",
      "INFO:tensorflow:loss = 14.50442, step = 2300 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.731\n",
      "INFO:tensorflow:loss = 14.513481, step = 2400 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.95\n",
      "INFO:tensorflow:loss = 9.803883, step = 2500 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.35\n",
      "INFO:tensorflow:loss = 12.003885, step = 2600 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.371\n",
      "INFO:tensorflow:loss = 12.596228, step = 2700 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.399\n",
      "INFO:tensorflow:loss = 13.808761, step = 2800 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.875\n",
      "INFO:tensorflow:loss = 10.536959, step = 2900 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.504\n",
      "INFO:tensorflow:loss = 11.75441, step = 3000 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.714\n",
      "INFO:tensorflow:loss = 9.37715, step = 3100 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.645\n",
      "INFO:tensorflow:loss = 13.869343, step = 3200 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.854\n",
      "INFO:tensorflow:loss = 15.88152, step = 3300 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.962\n",
      "INFO:tensorflow:loss = 12.141806, step = 3400 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.191\n",
      "INFO:tensorflow:loss = 13.194736, step = 3500 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.713\n",
      "INFO:tensorflow:loss = 10.32338, step = 3600 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.456\n",
      "INFO:tensorflow:loss = 7.0894628, step = 3700 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.961\n",
      "INFO:tensorflow:loss = 15.393148, step = 3800 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.615\n",
      "INFO:tensorflow:loss = 6.595225, step = 3900 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.586\n",
      "INFO:tensorflow:loss = 11.048062, step = 4000 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.343\n",
      "INFO:tensorflow:loss = 10.939441, step = 4100 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.257\n",
      "INFO:tensorflow:loss = 17.63771, step = 4200 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.072\n",
      "INFO:tensorflow:loss = 9.505396, step = 4300 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.02\n",
      "INFO:tensorflow:loss = 13.404327, step = 4400 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.488\n",
      "INFO:tensorflow:loss = 9.67683, step = 4500 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.052\n",
      "INFO:tensorflow:loss = 10.896845, step = 4600 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.526\n",
      "INFO:tensorflow:loss = 11.133998, step = 4700 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.978\n",
      "INFO:tensorflow:loss = 13.188222, step = 4800 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.28\n",
      "INFO:tensorflow:loss = 13.444435, step = 4900 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 206\n",
      "INFO:tensorflow:loss = 13.849655, step = 5000 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.775\n",
      "INFO:tensorflow:loss = 10.562619, step = 5100 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.549\n",
      "INFO:tensorflow:loss = 16.221212, step = 5200 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.712\n",
      "INFO:tensorflow:loss = 11.085018, step = 5300 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.229\n",
      "INFO:tensorflow:loss = 8.569147, step = 5400 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.022\n",
      "INFO:tensorflow:loss = 12.452816, step = 5500 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.596\n",
      "INFO:tensorflow:loss = 12.5020275, step = 5600 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.885\n",
      "INFO:tensorflow:loss = 12.0289, step = 5700 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.767\n",
      "INFO:tensorflow:loss = 10.758081, step = 5800 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.976\n",
      "INFO:tensorflow:loss = 15.215529, step = 5900 (0.494 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp4hit4amy\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.157311.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-01-12:44:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp4hit4amy\\model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-01-12:45:00\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.7, average_loss = 0.725354, global_step = 6000, loss = 5.579646\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp4hit4amy\\model.ckpt-6000\n",
      "Test Accuracy: 0.700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classifier\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = my_feature_columns,\n",
    "    #three hidden layers of 30 nodes each\n",
    "    hidden_units = [30, 30, 10],\n",
    "    #model must choose between 3 classes\n",
    "    n_classes=3\n",
    ")\n",
    "\n",
    "#train the model\n",
    "training_result = classifier.train(\n",
    "    input_fn = lambda: csv_input_fn(X_train,y_train, 16),\n",
    "    steps = 6000\n",
    ")\n",
    "\n",
    "\n",
    "#evaluate the model\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn = lambda: eval_input_fn(X_test, y_test, 8)\n",
    ")\n",
    "\n",
    "print(\"Test Accuracy:{accuracy: 0.3f}\\n\".format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!!!! Test Accuracy is **70%**. Now I can say this model is Minimum Viable Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serve an export function ###\n",
    "\n",
    "To serve predictions from this model, we need to export this model and save it in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serve_input_fn():\n",
    "    #create an future place holder\n",
    "    feature_placeholder = {}\n",
    "    \n",
    "    for cols in important_columns:\n",
    "        feature_placeholder.update({cols: tf.placeholder(tf.float32, [None])})\n",
    "    \n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholder.items()\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\MADHIV~1\\AppData\\Local\\Temp\\tmp4hit4amy\\model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      " Prediction is \"HomeTeam\" (81.725407%)\n",
      "\n",
      " Prediction is \"HomeTeam\" (80.895269%)\n",
      "\n",
      " Prediction is \"Draw\" (42.565513%)\n"
     ]
    }
   ],
   "source": [
    "expected = ['AwayTeam', 'Draw', 'HomeTeam']\n",
    "\n",
    "\n",
    "predict_x = {\n",
    "    'AC':[5.0, 7.0, 1.0, 4.0],\n",
    "    'AF':[17.0, 16.0, 12.0, 15.0],\n",
    "    'AR':[0.0, 0.0, 0.0, 0.0],\n",
    "    'AS':[19.0, 13.0, 9.0, 11.0],\n",
    "    'AST':[4.0, 1.0, 2.0, 2.0],\n",
    "    'AY':[2.0, 3.0, 1.0, 3.0],\n",
    "    'HC':[4.0, 3.0, 5.0, 6.0],\n",
    "    'HF':[13.0, 18.0, 18.0, 17.0],\n",
    "    'HR':[0.0, 0.0, 0.0, 0.0],\n",
    "    'HS':[13.0, 11.0, 10.0, 14.0],\n",
    "    'HST':[8.0, 5.0, 3.0, 3.0],\n",
    "    'HTAG':[0.0, 0.0, 0.0, 0.0],\n",
    "    'HTHG':[2.0, 1.0, 0.0, 0.0],\n",
    "    'HY':[1.0, 4.0, 2.0, 1.0],\n",
    "    'ht_label':[1.0, 6.0, 8.0, 9.0],\n",
    "    'at_label':[2.0, 3.0, 1.0, 3.0],\n",
    "    'league_label':[0.0, 0.0, 0.0, 0.0],\n",
    "    'HTCT':[1.0, 1.0, 0.0, 0.0],\n",
    "    'ATCT':[0.0, 0.0, 0.0, 0.0],\n",
    "    'HTWP':[0.21, 0.56, 0.31, 0.40],\n",
    "    'ATWP':[0.53, 0.23, 0.31, 0.71],\n",
    "}\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn = lambda : eval_input_fn(predict_x, labels=None, batch_size=4)\n",
    ")\n",
    "\n",
    "template = ('\\n Prediction is \"{}\" ({:1f}%)')\n",
    "\n",
    "for pred, expec in zip(predictions, expected):\n",
    "    class_id = pred['class_ids'][0]\n",
    "    probability = pred['probabilities'][class_id]\n",
    "    \n",
    "    print(template.format(expected[class_id], 100 * probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our model predicted the Probability of winning Team. For first, HomeTeam has high **HTWP(Home Team Wining Probability)** which is correct! For last data point, the model predicted **Draw** even though **ATWP** is high!",
    "If we want to improve the accuracy further, we can come up with new derived feature called **Team Possession**. Since, we have only **Half Time** goal data, to predict next half match goal Possession attribute helps us to predict",
    "Because, possession represents in what rate the ball is within the team itself. So, if possession rate is higher we can compare with Team winning probability and able to decide either the team wins the match in second half.",
    "If you find this attribute  useful, please try this feature, train the above model, share the accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
