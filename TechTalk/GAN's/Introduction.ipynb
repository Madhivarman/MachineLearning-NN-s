{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network(GAN's) ##\n",
    "\n",
    "GAN's are deep neural nets contains of two neural nets pittying against one another thus why it's called as **Adversarial Network**.\n",
    "\n",
    "\n",
    "## Invented By ##\n",
    "GANs were introduced in a paper by Ian Goodfellow and other researchers at the University of Montreal, including Yoshua Bengio, in 2014. Referring to GANs, Facebook’s AI research director Yann LeCun called adversarial training “the most interesting idea in the last 10 years in ML.”\n",
    "\n",
    "## Idea ##\n",
    "\n",
    "The idea is to train simultaneously two networks and competes again each other. \n",
    "\n",
    "1. Discriminator - Let's denote it D(y). It takes an input image abd outputs a scalar that indicates whether the input image is real or not.  In simple terms,\n",
    "                If D(y)=0,\n",
    "                    then Real\n",
    "                else\n",
    "                   D(y)=1. then Fake\n",
    "    The closer D(Y) to zero, the real the image gets.\n",
    " \n",
    "2. Generator - Let's denote it G(z). z is the randomly sampled vector in a simple distribution. The role of Generator is to produce an input image similar to D(Y) from the randomly Sampled vector. The goal is to train D(Y) to take into a  right shape. During Training D is shown an real image to adjust its parameter to make it lower. well G(z) will produce its own input image from the randomly noise vector thinking that it is the real image and adjust it parameter to make D(G(z)) as larger.  G(z) will produce the input image from the random distribution and then D will shown the image produced by G. If the D identifies the image is fake, the gradient of image (Y) will be passed back to G for each sample it produces. In other words, the Generator will try to minimize the output of D while Discriminator tries larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underlying Idea ##\n",
    "\n",
    "### Interpreting images from Random Sample from a probability distribution ###\n",
    "\n",
    "![randomImage](images/completion.compressed.gif)\n",
    "\n",
    "Probability distribution plays a major role in image processing and deep learning. For example, lets take an above picture that we know some values and want to complete the missing value. Just pose it as a maximization problem where we search over all of the  possible missing values. however, applying this method in practise is easy to recover for simple distributions, its difficult and often interactable for complex distribution over images. The complexity partly comes from [conditional dependencies], the value of one pixel completely depends on another. Also maximizing the PDF for an image might be difficult and often intractable non-convex optimization problem.\n",
    "\n",
    "\n",
    "### Overall Layer of GAN ###\n",
    "![ganschema](images/gan_schema.png)\n",
    "\n",
    "The both models are multilayer perceptron. To learn generator's distribution data p<sub>(g) over data X, we define a prior on input noise variable p<sub>z(Z), then represents mapping data into higher dimensional space. G(z;theta(g)) where G is the differentiable function represented by multilayer perceptron with parameters theta(g).  \n",
    "    \n",
    "D(x, theta(d)) is the scalar value which comes from the second layer of perceptron. It describes probability of x rather the p<sub>(g). We simultaneously train generator G to minimize\n",
    "                1 - log(D(G(z))\n",
    "\n",
    "\n",
    "The loss function will be\n",
    "\n",
    "![ganLossFunction](images/gan_loss.png)\n",
    "\n",
    "\n",
    "\n",
    "In the inner loop of algorithm D is trained to discriminate samples from data, converging \n",
    "\n",
    "            D<sup>*(x) = p<sub>(data)(x) / (p<sub>(data)(x) + p<sub>(g)(x)\n",
    "\n",
    "After an update to G, gradient of D has guided G(z) to flow regions that are more likely classified to be as data.(ie.., Discriminator will help generator to help its distribution of the data).\n",
    "\n",
    "After several steps of training, if G and D achieved its enough capacity, they will reach a point at which both cannot improve because p<sub>(g) = p<sub>data(X). The discriminator is unable to differentiate between two distributions.\n",
    "\n",
    "![ganDistribution](images/gan_distribution.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Comparisons ##\n",
    "#### Different between Variational AutoEncoders and GAN's ####\n",
    "\n",
    "Both GAN's and Autoencoders are generative models, which means they learn a distribution of model rather then its density. \n",
    "\n",
    "Autoencoders learn a given distribution comparing its input to produce output. Autoencoders are good for learning hidden representation. It's bad for creating a new data because it learns the generalized distribution of data and producing images on that data produce blurry image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
