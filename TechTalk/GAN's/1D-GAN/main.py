import numpy as np
import keras
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras.utils.vis_utils import plot_model

#generte random sample for 1d data
def generate_random_sample(n=1000):
	#generate random inputs between -2.0 to 2.0
	X1 = np.random.rand(n) - 0.5
	X2 = X1 * X1
	#stack arrays
	#before reshape into tensors
	X1 = X1.reshape(n, 1)
	X2 = X2.reshape(n, 1)

	return np.hstack((X1, X2))


#helper function helps us to create a label
#class
def generate_real_sample(n):
	#generate inputs between -2 and 2
	X1 = np.random.randn(n)-0.5
	X2 = X1* X1
	#reshape
	X1 = X1.reshape(n, 1)
	X2 = X2.reshape(n, 1)
	#generate class labels
	X = np.hstack((X1, X2))
	y = np.ones(n)

	return X, y

def plot_raw_data(data, filename):
	plt.scatter(data[:, 0], data[:, 1])
	plt.savefig(filename)
	plt.show()

#creating a discriminator network
"""
	 the role of discriminator network is to
	 classify whether the output generated by
	 Generator is real or not.
"""
def discriminator(n_inputs=2):
	model = Sequential()
	model.add(Dense(25, activation='relu', kernel_initializer='he_uniform',
		input_dim=n_inputs))
	model.add(Dense(15, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dense(10, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dense(1, activation='sigmoid'))
	model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

	return model

#function where generator tries to generate the 
#input image and GAN network will evaluate the 
#loss of the network.

#the goal is to maximize the accuracy for fake_image generated
#and reduce the loss.
def generate_fake_samples(generator, latent_dim, n):
	x_input = norm_distributions(latent_dim, n)
	X = generator.predict(x_input)
	y = np.zeros((n, 1))

	return X, y


#creating a generator network
"""
	generator network takes an input from latent space,
	generates a new sample
"""
def norm_distributions(latent_dim, n):
	x_input = np.random.randn(latent_dim * n)
	x_input = x_input.reshape(n, latent_dim)
	return x_input

def generator(latent_dim, n_outputs=2):
	model = Sequential()
	model.add(Dense(15, activation='relu', kernel_initializer='he_uniform',
		input_dim=latent_dim))
	model.add(Dense(n_outputs, activation='linear'))

	return model

def GAN(generator, discriminator):
	#make weights in discriminator not trainable
	discriminator.trainable = False 

	model = Sequential()
	model.add(generator)
	model.add(discriminator)

	model.compile(loss='binary_crossentropy', optimizer='adam')
	return model

def summarize_performance(epochs, generator, discriminator, latent_dim,n=100):
	plt.figure(figsize=(20, 10))
	#prepare real samples
	x_real, y_real = generate_real_sample(n)
	#evalute discriminator on real samples
	dis_real_loss, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)
	#prepare fake example
	x_fake, y_fake = generate_fake_samples(generator, latent_dim, n)
	#evaluate discriminator on fake samples
	dis_fake_loss, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)

	with open("logs.txt", "a") as fp:
		fp.write("steps:{}, real loss:{}, fake_loss:{}".format(epochs, dis_real_loss, dis_fake_loss))
		fp.write("\n")
		fp.write("          real accuracy:{}, fake_acc:{}".format(acc_real, acc_fake))
		fp.write("\n")
		fp.close()

	print("steps:{}, real loss:{}, fake_loss:{}".
		format(epochs, dis_real_loss, dis_fake_loss))
	print("          real acc:{}, fake_acc:{}".
		format(acc_real, acc_fake))

	plt.scatter(x_real[:, 0], x_real[:, 1], color='blue', label='real distribution')
	plt.scatter(x_fake[:, 0], x_fake[:, 1], color='red', label='generator distribution')

	plt.legend()
	plt.savefig("imagesGenerated/epochs_{}.jpg".format(epochs))
	#plt.show()


def train(g_model, d_model, gan_model, latent_dim,
			 n_epochs=2000,n_batches=128, n_eval=100):
	
	half_batch = int(n_batches/2)

	#iterate through epochs
	for i in range(n_epochs):
		#prepare real samples
		x_real, y_real = generate_real_sample(half_batch)
		x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)

		#update discriminator
		real_loss = d_model.train_on_batch(x_real, y_real)
		fake_loss = d_model.train_on_batch(x_fake, y_fake)

		#latent space as inputs for the generator
		x_gan = norm_distributions(latent_dim, n_batches)
		y_gan = np.ones((n_batches, 1))

		#update the generator via discriminator error
		gan_model.train_on_batch(x_gan, y_gan)

		#evaluate the model
		if (i+1) % n_eval == 0:
			summarize_performance(i, g_model, d_model, latent_dim)



def main():
	data = generate_random_sample()
	latent_dim = 5

	#defining a networks
	D = discriminator()
	G = generator(latent_dim)
	gan = GAN(G, D)

	#start training
	train(G, D, gan, latent_dim)

if __name__ == '__main__':
	main()

